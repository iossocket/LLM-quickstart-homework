{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "34c80fbe3c2d448a9c4bc48b4beebc27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efa6c854043444ebac7946c2d2ae2eb0",
              "IPY_MODEL_0575b6eb31c1484a952d2f2597c6439a",
              "IPY_MODEL_7c8c6f1c998e4a21986a557e95ebb830"
            ],
            "layout": "IPY_MODEL_777a13412ae748b88efce44c91cc4f36"
          }
        },
        "efa6c854043444ebac7946c2d2ae2eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8347c36cba54b48adaade26c959fe7b",
            "placeholder": "​",
            "style": "IPY_MODEL_0896b4ed0fc048a9ad2a8a44db5b55c5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0575b6eb31c1484a952d2f2597c6439a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40ef91b4808342f78faff72f9712793c",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd0554513d564fa4911ef3e1a7f10909",
            "value": 7
          }
        },
        "7c8c6f1c998e4a21986a557e95ebb830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_050e6e49e3bc4b76b4f1dcad118f199c",
            "placeholder": "​",
            "style": "IPY_MODEL_ad5b4a04a0664df2abb2085df20bf17d",
            "value": " 7/7 [00:05&lt;00:00,  1.41it/s]"
          }
        },
        "777a13412ae748b88efce44c91cc4f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8347c36cba54b48adaade26c959fe7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0896b4ed0fc048a9ad2a8a44db5b55c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40ef91b4808342f78faff72f9712793c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0554513d564fa4911ef3e1a7f10909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "050e6e49e3bc4b76b4f1dcad118f199c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad5b4a04a0664df2abb2085df20bf17d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ceebde7e5a364531904ea0909a4c0f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5640a69787040b29ae04a435029157f",
              "IPY_MODEL_a0c0753525c94dea91260ca9e432bfc3",
              "IPY_MODEL_06889ed18bd94a91a8b1c70334142293"
            ],
            "layout": "IPY_MODEL_ba1595ffdf9847408361c2cbc2fe52c8"
          }
        },
        "e5640a69787040b29ae04a435029157f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8637bb75da81495d833318b9893e5bef",
            "placeholder": "​",
            "style": "IPY_MODEL_40dfaf4827044181963b5a5a69e8e302",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a0c0753525c94dea91260ca9e432bfc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b709b014207433d86213d1955345a82",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3eb5e6d6e9c4123861799ee41570fdc",
            "value": 7
          }
        },
        "06889ed18bd94a91a8b1c70334142293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43c4e23b1d724c089f47368a1819adeb",
            "placeholder": "​",
            "style": "IPY_MODEL_aad2c58b546441a182feeeaa75f0c571",
            "value": " 7/7 [00:05&lt;00:00,  1.36it/s]"
          }
        },
        "ba1595ffdf9847408361c2cbc2fe52c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8637bb75da81495d833318b9893e5bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40dfaf4827044181963b5a5a69e8e302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b709b014207433d86213d1955345a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3eb5e6d6e9c4123861799ee41570fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43c4e23b1d724c089f47368a1819adeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aad2c58b546441a182feeeaa75f0c571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbE5BzGgcCl2",
        "outputId": "9250f088-589d-475c-e032-7588e9f4d28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 1)) (2.1.0+cu121)\n",
            "Collecting transformers==4.37.2 (from -r r.txt (line 2))\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ffmpeg in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 3)) (1.4)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 5)) (0.9.16)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 7)) (0.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 8)) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 9)) (1.5.3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 10)) (0.9.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 11)) (0.27.2)\n",
            "Requirement already satisfied: autoawq in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 12)) (0.2.3)\n",
            "Requirement already satisfied: optimum in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 13)) (1.17.1)\n",
            "Requirement already satisfied: auto-gptq in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 14)) (0.7.1)\n",
            "Requirement already satisfied: bitsandbytes>0.39.0 in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 15)) (0.42.0)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 16)) (3.0.3)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 17)) (0.12.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 18)) (0.10.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 19)) (0.1.11)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (from -r r.txt (line 20)) (4.19.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r r.txt (line 2)) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r r.txt (line 2)) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r r.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r r.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r r.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r r.txt (line 2)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r r.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r r.txt (line 2)) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r r.txt (line 2)) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r r.txt (line 2)) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r r.txt (line 1)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r r.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r r.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r r.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r r.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r r.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python->-r r.txt (line 4)) (0.18.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->-r r.txt (line 5)) (0.16.0+cu121)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r r.txt (line 6)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r r.txt (line 6)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r r.txt (line 6)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r r.txt (line 6)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->-r r.txt (line 6)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r r.txt (line 6)) (3.9.3)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate->-r r.txt (line 7)) (0.18.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r r.txt (line 8)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r r.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r r.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r r.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r r.txt (line 9)) (2023.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft->-r r.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from autoawq->-r r.txt (line 12)) (0.22.0)\n",
            "Requirement already satisfied: autoawq-kernels in /usr/local/lib/python3.10/dist-packages (from autoawq->-r r.txt (line 12)) (0.0.6)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum->-r r.txt (line 13)) (15.0.1)\n",
            "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from optimum->-r r.txt (line 13)) (4.38.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-gptq->-r r.txt (line 14)) (0.1.99)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto-gptq->-r r.txt (line 14)) (1.0.1)\n",
            "Requirement already satisfied: gekko in /usr/local/lib/python3.10/dist-packages (from auto-gptq->-r r.txt (line 14)) (1.0.6)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer->-r r.txt (line 16)) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer->-r r.txt (line 16)) (3.6.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->-r r.txt (line 17)) (1.16.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->-r r.txt (line 18)) (3.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r r.txt (line 18)) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r r.txt (line 18)) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r r.txt (line 18)) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r r.txt (line 18)) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r r.txt (line 18)) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r r.txt (line 18)) (1.0.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r r.txt (line 19)) (2.0.27)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r r.txt (line 19)) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain->-r r.txt (line 19)) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain->-r r.txt (line 19)) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.25 in /usr/local/lib/python3.10/dist-packages (from langchain->-r r.txt (line 19)) (0.0.25)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.29 in /usr/local/lib/python3.10/dist-packages (from langchain->-r r.txt (line 19)) (0.1.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r r.txt (line 19)) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain->-r r.txt (line 19)) (0.1.19)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r r.txt (line 19)) (2.6.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r r.txt (line 19)) (8.2.3)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (0.110.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.10.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (0.10.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (0.27.0)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (6.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (3.7.1)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (3.9.15)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (9.4.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (0.0.9)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (0.3.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (0.9.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r r.txt (line 20)) (0.27.1)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.10.1->gradio->-r r.txt (line 20)) (11.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r r.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r r.txt (line 6)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r r.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r r.txt (line 6)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r r.txt (line 6)) (1.9.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r r.txt (line 20)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r r.txt (line 20)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r r.txt (line 20)) (0.12.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->-r r.txt (line 17)) (2.21)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r r.txt (line 19)) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r r.txt (line 19)) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r r.txt (line 20)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r r.txt (line 20)) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r r.txt (line 20)) (1.0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r r.txt (line 20)) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r r.txt (line 20)) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r r.txt (line 20)) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain->-r r.txt (line 19)) (2.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r r.txt (line 20)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r r.txt (line 20)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r r.txt (line 20)) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r r.txt (line 20)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r r.txt (line 20)) (3.1.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->-r r.txt (line 18)) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->-r r.txt (line 18)) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r r.txt (line 19)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r r.txt (line 19)) (2.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->-r r.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2->-r r.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2->-r r.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r r.txt (line 19)) (3.0.3)\n",
            "INFO: pip is looking at multiple versions of transformers[sentencepiece] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting transformers[sentencepiece]>=4.26.0 (from optimum->-r r.txt (line 13))\n",
            "  Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.38.0-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r r.txt (line 2)) (3.20.3)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r r.txt (line 20)) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r r.txt (line 20)) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r r.txt (line 20)) (13.7.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum->-r r.txt (line 13)) (10.0)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r r.txt (line 20)) (0.36.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->-r r.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio->-r r.txt (line 20)) (1.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r r.txt (line 20)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r r.txt (line 20)) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r r.txt (line 20)) (0.18.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r r.txt (line 20)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r r.txt (line 20)) (2.16.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->-r r.txt (line 19)) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r r.txt (line 20)) (0.1.2)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.1\n",
            "    Uninstalling transformers-4.38.1:\n",
            "      Successfully uninstalled transformers-4.38.1\n",
            "Successfully installed transformers-4.37.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -r r.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义全局变量和参数\n",
        "model_name_or_path = 'THUDM/chatglm3-6b'  # 模型ID或本地路径\n",
        "# train_data_path = 'data/zhouyi_dataset_handmade.csv'    # 训练数据路径\n",
        "train_data_path = 'zhouyi_dataset_20240118_163659.csv'    # 训练数据路径(批量生成数据集）\n",
        "eval_data_path = None                     # 验证数据路径，如果没有则设置为None\n",
        "seed = 8                                 # 随机种子\n",
        "max_input_length = 512                    # 输入的最大长度\n",
        "max_output_length = 1536                  # 输出的最大长度\n",
        "lora_rank = 16                             # LoRA秩\n",
        "lora_alpha = 32                           # LoRA alpha值\n",
        "lora_dropout = 0.05                       # LoRA Dropout率\n",
        "prompt_text = ''"
      ],
      "metadata": {
        "id": "rX90EwpUcnUx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"csv\", data_files=train_data_path)\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIwss9x7cx1e",
        "outputId": "bf8e7eff-ad07-4101-d35f-a2028ef06a10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['content', 'summary'],\n",
            "        num_rows: 160\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path,\n",
        "                                          trust_remote_code=True,\n",
        "                                          revision='b098244')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb5KLZVtcz2V",
        "outputId": "f1f68f28-d5b9-4d44-fd0c-ee703618f3cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize_func 函数\n",
        "def tokenize_func(example, tokenizer, ignore_label_id=-100):\n",
        "    \"\"\"\n",
        "    对单个数据样本进行tokenize处理。\n",
        "\n",
        "    参数:\n",
        "    example (dict): 包含'content'和'summary'键的字典，代表训练数据的一个样本。\n",
        "    tokenizer (transformers.PreTrainedTokenizer): 用于tokenize文本的tokenizer。\n",
        "    ignore_label_id (int, optional): 在label中用于填充的忽略ID，默认为-100。\n",
        "\n",
        "    返回:\n",
        "    dict: 包含'tokenized_input_ids'和'labels'的字典，用于模型训练。\n",
        "    \"\"\"\n",
        "\n",
        "    # 构建问题文本\n",
        "    question = prompt_text + example['content']\n",
        "    if example.get('input', None) and example['input'].strip():\n",
        "        question += f'\\n{example[\"input\"]}'\n",
        "\n",
        "    # 构建答案文本\n",
        "    answer = example['summary']\n",
        "\n",
        "    # 对问题和答案文本进行tokenize处理\n",
        "    q_ids = tokenizer.encode(text=question, add_special_tokens=False)\n",
        "    a_ids = tokenizer.encode(text=answer, add_special_tokens=False)\n",
        "\n",
        "    # 如果tokenize后的长度超过最大长度限制，则进行截断\n",
        "    if len(q_ids) > max_input_length - 2:  # 保留空间给gmask和bos标记\n",
        "        q_ids = q_ids[:max_input_length - 2]\n",
        "    if len(a_ids) > max_output_length - 1:  # 保留空间给eos标记\n",
        "        a_ids = a_ids[:max_output_length - 1]\n",
        "\n",
        "    # 构建模型的输入格式\n",
        "    input_ids = tokenizer.build_inputs_with_special_tokens(q_ids, a_ids)\n",
        "    question_length = len(q_ids) + 2  # 加上gmask和bos标记\n",
        "\n",
        "    # 构建标签，对于问题部分的输入使用ignore_label_id进行填充\n",
        "    labels = [ignore_label_id] * question_length + input_ids[question_length:]\n",
        "\n",
        "    return {'input_ids': input_ids, 'labels': labels}"
      ],
      "metadata": {
        "id": "OBt-ED2Mc17t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = dataset['train'].column_names\n",
        "tokenized_dataset = dataset['train'].map(\n",
        "    lambda example: tokenize_func(example, tokenizer),\n",
        "    batched=False,\n",
        "    remove_columns=column_names\n",
        ")\n",
        "tokenized_dataset = tokenized_dataset.shuffle(seed=seed)\n",
        "tokenized_dataset = tokenized_dataset.flatten_indices()"
      ],
      "metadata": {
        "id": "oNOWuEacc4zQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "# DataCollatorForChatGLM 类\n",
        "class DataCollatorForChatGLM:\n",
        "    \"\"\"\n",
        "    用于处理批量数据的DataCollator，尤其是在使用 ChatGLM 模型时。\n",
        "\n",
        "    该类负责将多个数据样本（tokenized input）合并为一个批量，并在必要时进行填充(padding)。\n",
        "\n",
        "    属性:\n",
        "    pad_token_id (int): 用于填充(padding)的token ID。\n",
        "    max_length (int): 单个批量数据的最大长度限制。\n",
        "    ignore_label_id (int): 在标签中用于填充的ID。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pad_token_id: int, max_length: int = 2048, ignore_label_id: int = -100):\n",
        "        \"\"\"\n",
        "        初始化DataCollator。\n",
        "\n",
        "        参数:\n",
        "        pad_token_id (int): 用于填充(padding)的token ID。\n",
        "        max_length (int): 单个批量数据的最大长度限制。\n",
        "        ignore_label_id (int): 在标签中用于填充的ID，默认为-100。\n",
        "        \"\"\"\n",
        "        self.pad_token_id = pad_token_id\n",
        "        self.ignore_label_id = ignore_label_id\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __call__(self, batch_data: List[Dict[str, List]]) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        处理批量数据。\n",
        "\n",
        "        参数:\n",
        "        batch_data (List[Dict[str, List]]): 包含多个样本的字典列表。\n",
        "\n",
        "        返回:\n",
        "        Dict[str, torch.Tensor]: 包含处理后的批量数据的字典。\n",
        "        \"\"\"\n",
        "        # 计算批量中每个样本的长度\n",
        "        len_list = [len(d['input_ids']) for d in batch_data]\n",
        "        batch_max_len = max(len_list)  # 找到最长的样本长度\n",
        "\n",
        "        input_ids, labels = [], []\n",
        "        for len_of_d, d in sorted(zip(len_list, batch_data), key=lambda x: -x[0]):\n",
        "            pad_len = batch_max_len - len_of_d  # 计算需要填充的长度\n",
        "            # 添加填充，并确保数据长度不超过最大长度限制\n",
        "            ids = d['input_ids'] + [self.pad_token_id] * pad_len\n",
        "            label = d['labels'] + [self.ignore_label_id] * pad_len\n",
        "            if batch_max_len > self.max_length:\n",
        "                ids = ids[:self.max_length]\n",
        "                label = label[:self.max_length]\n",
        "            input_ids.append(torch.LongTensor(ids))\n",
        "            labels.append(torch.LongTensor(label))\n",
        "\n",
        "        # 将处理后的数据堆叠成一个tensor\n",
        "        input_ids = torch.stack(input_ids)\n",
        "        labels = torch.stack(labels)\n",
        "\n",
        "        return {'input_ids': input_ids, 'labels': labels}"
      ],
      "metadata": {
        "id": "MjDuE63Vc8UV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 准备数据整理器\n",
        "data_collator = DataCollatorForChatGLM(pad_token_id=tokenizer.pad_token_id)"
      ],
      "metadata": {
        "id": "dCXeahEFdAB-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, BitsAndBytesConfig\n",
        "\n",
        "_compute_dtype_map = {\n",
        "    'fp32': torch.float32,\n",
        "    'fp16': torch.float16,\n",
        "    'bf16': torch.bfloat16\n",
        "}\n",
        "\n",
        "# QLoRA 量化配置\n",
        "q_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                              bnb_4bit_quant_type='nf4',\n",
        "                              bnb_4bit_use_double_quant=True,\n",
        "                              bnb_4bit_compute_dtype=_compute_dtype_map['bf16'])\n",
        "# 加载量化后模型\n",
        "model = AutoModel.from_pretrained(model_name_or_path,\n",
        "                                  quantization_config=q_config,\n",
        "                                  device_map='auto',\n",
        "                                  trust_remote_code=True,\n",
        "                                  revision='b098244')\n",
        "\n",
        "model.supports_gradient_checkpointing = True\n",
        "model.gradient_checkpointing_enable()\n",
        "model.enable_input_require_grads()\n",
        "\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "34c80fbe3c2d448a9c4bc48b4beebc27",
            "efa6c854043444ebac7946c2d2ae2eb0",
            "0575b6eb31c1484a952d2f2597c6439a",
            "7c8c6f1c998e4a21986a557e95ebb830",
            "777a13412ae748b88efce44c91cc4f36",
            "a8347c36cba54b48adaade26c959fe7b",
            "0896b4ed0fc048a9ad2a8a44db5b55c5",
            "40ef91b4808342f78faff72f9712793c",
            "bd0554513d564fa4911ef3e1a7f10909",
            "050e6e49e3bc4b76b4f1dcad118f199c",
            "ad5b4a04a0664df2abb2085df20bf17d"
          ]
        },
        "id": "jxrU7c_JdC9j",
        "outputId": "91fb8ec3-28f1-45a5-d3b6-3618d7789283"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34c80fbe3c2d448a9c4bc48b4beebc27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import TaskType, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from peft.utils import TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING\n",
        "\n",
        "kbit_model = prepare_model_for_kbit_training(model)\n",
        "target_modules = TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING['chatglm']\n",
        "lora_config = LoraConfig(\n",
        "    target_modules=target_modules,\n",
        "    r=lora_rank,\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    bias='none',\n",
        "    inference_mode=False,\n",
        "    task_type=TaskType.CAUSAL_LM\n",
        ")\n",
        "qlora_model = get_peft_model(kbit_model, lora_config)\n",
        "qlora_model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB6FqAc6dE7o",
        "outputId": "44e56e07-67ec-4ffb-8e13-ec636bde40e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 3,899,392 || all params: 6,247,483,392 || trainable%: 0.06241540401681151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "train_epochs = 3\n",
        "output_dir = f\"models/{model_name_or_path}-epoch{train_epochs}-{timestamp}\""
      ],
      "metadata": {
        "id": "-Kpp9Nu3eS40"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,                            # 输出目录\n",
        "    per_device_train_batch_size=8,                     # 每个设备的训练批量大小\n",
        "    gradient_accumulation_steps=1,                     # 梯度累积步数\n",
        "    learning_rate=1e-3,                                # 学习率\n",
        "    num_train_epochs=train_epochs,                     # 训练轮数\n",
        "    lr_scheduler_type=\"linear\",                        # 学习率调度器类型\n",
        "    warmup_ratio=0.1,                                  # 预热比例\n",
        "    logging_steps=1,                                 # 日志记录步数\n",
        "    save_strategy=\"steps\",                             # 模型保存策略\n",
        "    save_steps=10,                                    # 模型保存步数\n",
        "    optim=\"adamw_torch\",                               # 优化器类型\n",
        "    fp16=True,                                        # 是否使用混合精度训练\n",
        ")\n",
        "trainer = Trainer(\n",
        "        model=qlora_model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_dataset,\n",
        "        data_collator=data_collator\n",
        "    )\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ttU62be0ebr7",
        "outputId": "e6fd1d3f-058c-4793-f324-bdbb5112120b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 02:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.672500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.700800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.272200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.396300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.954400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.687600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>3.529300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>3.144000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>3.019400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.763400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.546000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.244400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.724600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.841500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.500300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.520100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.089200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.764700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.845900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.600600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.442800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.284700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.271800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.192800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.125600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.088800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.055600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.067200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.035000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.049200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.026700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.021400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.018000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.018800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.014200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.013900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.011600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.008800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.007400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.007300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.006100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.006100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=60, training_loss=0.9116342000197619, metrics={'train_runtime': 128.5584, 'train_samples_per_second': 3.734, 'train_steps_per_second': 0.467, 'total_flos': 4623664398827520.0, 'train_loss': 0.9116342000197619, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "D1jyCyvjes6o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "# 模型ID或本地路径\n",
        "model_name_or_path = 'THUDM/chatglm3-6b'\n",
        "\n",
        "_compute_dtype_map = {\n",
        "    'fp32': torch.float32,\n",
        "    'fp16': torch.float16,\n",
        "    'bf16': torch.bfloat16\n",
        "}\n",
        "\n",
        "# QLoRA 量化配置\n",
        "q_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                              bnb_4bit_quant_type='nf4',\n",
        "                              bnb_4bit_use_double_quant=True,\n",
        "                              bnb_4bit_compute_dtype=_compute_dtype_map['bf16'])\n",
        "\n",
        "# 加载量化后模型(与微调的 revision 保持一致）\n",
        "base_model = AutoModel.from_pretrained(model_name_or_path,\n",
        "                                      quantization_config=q_config,\n",
        "                                      device_map='auto',\n",
        "                                      trust_remote_code=True,\n",
        "                                      revision='b098244')\n",
        "\n",
        "base_model.requires_grad_(False)\n",
        "base_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694,
          "referenced_widgets": [
            "ceebde7e5a364531904ea0909a4c0f01",
            "e5640a69787040b29ae04a435029157f",
            "a0c0753525c94dea91260ca9e432bfc3",
            "06889ed18bd94a91a8b1c70334142293",
            "ba1595ffdf9847408361c2cbc2fe52c8",
            "8637bb75da81495d833318b9893e5bef",
            "40dfaf4827044181963b5a5a69e8e302",
            "7b709b014207433d86213d1955345a82",
            "c3eb5e6d6e9c4123861799ee41570fdc",
            "43c4e23b1d724c089f47368a1819adeb",
            "aad2c58b546441a182feeeaa75f0c571"
          ]
        },
        "id": "pTl2X4CrfQEY",
        "outputId": "62e9ea1b-3c0f-4b2b-9287-19fea4c674ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ceebde7e5a364531904ea0909a4c0f01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGLMForConditionalGeneration(\n",
              "  (transformer): ChatGLMModel(\n",
              "    (embedding): Embedding(\n",
              "      (word_embeddings): Embedding(65024, 4096)\n",
              "    )\n",
              "    (rotary_pos_emb): RotaryEmbedding()\n",
              "    (encoder): GLMTransformer(\n",
              "      (layers): ModuleList(\n",
              "        (0-27): 28 x GLMBlock(\n",
              "          (input_layernorm): RMSNorm()\n",
              "          (self_attention): SelfAttention(\n",
              "            (query_key_value): Linear4bit(in_features=4096, out_features=4608, bias=True)\n",
              "            (core_attention): CoreAttention(\n",
              "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (dense): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          )\n",
              "          (post_attention_layernorm): RMSNorm()\n",
              "          (mlp): MLP(\n",
              "            (dense_h_to_4h): Linear4bit(in_features=4096, out_features=27392, bias=False)\n",
              "            (dense_4h_to_h): Linear4bit(in_features=13696, out_features=4096, bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layernorm): RMSNorm()\n",
              "    )\n",
              "    (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path,\n",
        "                                          trust_remote_code=True,\n",
        "                                          revision='b098244')"
      ],
      "metadata": {
        "id": "dfFiu7s1f0jm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"解释下乾卦是什么？\"\n",
        "response, history = base_model.chat(tokenizer, query=input_text)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGnXfwQkf-En",
        "outputId": "8b2e9115-9d92-4e5d-867f-77764778d9e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "乾卦是八卦之一，也是八宫图中的第一个卦。乾卦是由两个阳爻夹一个阴爻构成，象征着天、云、雷等阳性的气象现象。乾卦的含义包括力量、刚强、积极、创造、领导等，它是一种积极向上的态度和能量。\n",
            "\n",
            "在八宫图中，乾卦位于北方，与事业、努力、刚强、决断等有关。它代表了一个人的事业、努力、决断和领导能力。乾卦也象征着一种坚定的决心和勇气，以及追求成功的精神。\n",
            "\n",
            "在易经中，乾卦的卦辞是“元、亨、利、贞”，意味着“元始、亨通、顺利、正道”。它是一种积极的、向上的、创造性的能量，代表着人们不断追求进步和发展的愿望。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response, history = base_model.chat(tokenizer, query=\"周易中的讼卦是什么？\", history=history)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhqqwRXNgCB8",
        "outputId": "0064f2b2-2aac-4e5e-a7c9-34c24f35798b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "周易中的讼卦（也称法卦）是八卦之一，它的卦象是由两个阴爻夹一个阳爻构成，象征着天、云、雷等阳性的气象现象。讼卦的含义包括诉讼、争斗、诉讼、法则等，它主要涉及到法律、法规、规则、条文等方面的内容。\n",
            "\n",
            "在八宫图中，讼卦位于西北方，与法律、法规、制度、条文等有关。它代表了一个人的法律意识、法规意识、规则意识和条文意识。讼卦也象征着一种坚持正义、维护公平的态度和能量。\n",
            "\n",
            "在易经中，讼卦的卦辞是“元、亨、利、贞”，意味着“元始、亨通、顺利、正道”。它是一种积极的、向上的、创造性的能量，代表着人们不断追求进步和发展的愿望。同时，讼卦也提醒人们要遵守法律法规，尊重社会秩序，坚持公平正义。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "epochs = 3\n",
        "timestamp = \"20240305_115725\"\n",
        "\n",
        "peft_model_path = f\"models/{model_name_or_path}-epoch{epochs}-{timestamp}\"\n",
        "\n",
        "config = PeftConfig.from_pretrained(peft_model_path)\n",
        "qlora_model = PeftModel.from_pretrained(base_model, peft_model_path)\n",
        "training_tag=f\"ChatGLM3-6B(Epoch=3, automade-dataset(fixed))-{timestamp}\""
      ],
      "metadata": {
        "id": "TGX0_xQ-gJ1k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_chatglm_results(query, base_model, qlora_model, training_tag):\n",
        "    base_response, base_history = base_model.chat(tokenizer, query)\n",
        "\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\").to(0)\n",
        "    ft_out = qlora_model.generate(**inputs, max_new_tokens=512)\n",
        "    ft_response = tokenizer.decode(ft_out[0], skip_special_tokens=True)\n",
        "\n",
        "    print(f\"问题：{query}\\n\\n原始输出：\\n{base_response}\\n\\n\\n微调后（{training_tag}）：\\n{ft_response}\")\n",
        "    return base_response, ft_response"
      ],
      "metadata": {
        "id": "1AC4ntHCgdib"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_response, ft_response = compare_chatglm_results(\"解释下乾卦是什么？\", base_model, qlora_model, training_tag)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0UYdkstgwFy",
        "outputId": "5eb55eae-f524-4411-ee20-98042d437b55"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "问题：解释下乾卦是什么？\n",
            "\n",
            "原始输出：\n",
            "乾卦是周易中的一卦，由两个乾卦叠加而成，代表天。它是一个阳卦，代表着君子。在卜卦中，它预示着君子们能够获得成功的机遇。乾卦象征着天，代表着君子应该君子模擬天道，刚健不欺软，刚健不欺软，正派 marco，严格恭俭，适當地前进。在事业、经商、求名、婚恋等方面，乾卦都表示着君子能够得到成功的机遇，但需谨慎恭俭。在决策时，应该严格谨慎地分析和判断，顺应天道，象天道一样刚健不欺软。在经商中，它预示着经商者应该君子式地活跃于商场，但 also需要警惕可能会出现的困难。在求名方面，乾卦提示着名利之星，需要谨慎谨慎地追求。在婚恋方面，它预示着婚姻星辰，需要谨慎选择，寻找理想的伴侣。乾卦的核心思想是：君子刚健不欺软，正派 marco，严格恭俭，适当地前进，在事业、经商、求名、婚恋等方面，都需要谨慎谨慎地分析和判断。\n",
            "\n",
            "\n",
            "微调后（ChatGLM3-6B(Epoch=3, automade-dataset(fixed))-20240305_115725）：\n",
            "[gMASK]sop 解释下乾卦是什么？ 在周易中，乾卦是六十四卦之首，由六个阳爻组成，象征着天。它所代表的是刚健、健行、刚健不屈的意境。乾卦的核心哲学是：天道刚健，运行不已，君子观此卦象，从而以天为法，自强不息。\n",
            "\n",
            "乾卦象征天，为大通而至正。得此卦者，名利双收，应把握机会，争取成果。然而，切勿过于骄傲自满，而应保持谦逊、冷静和警惕。在事业、经商、求名等方面，乾卦皆暗示着大吉大利，但也警示着必须坚持正道、修养德行，方能永远亨通。\n",
            "\n",
            "在婚恋方面，乾卦提示着阳盛阴衰，但也强调刚柔相济，相互补足，形成美满的结果。在决策方面，则是强调刚健、正直、公允，自强不息的实质，需要修养德行、坚定信念，方能克服困难，消除灾难。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RdaaO29dgyxD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}